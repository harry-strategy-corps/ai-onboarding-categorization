{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 05 — Evaluate Transaction Categorization Accuracy\n",
    "\n",
    "**Objective:** Compare LLM predictions from `04_transaction_categorization_test` against the Master Fee Table ground truth.\n",
    "\n",
    "### Metrics\n",
    "1. **Per-Level Accuracy** — L1, L2, L3, L4 independently (case-insensitive).\n",
    "2. **Exact Match** — All 4 levels correct.\n",
    "3. **Partial Match** — L1 + L2 correct (right block and category).\n",
    "4. **Volume-Weighted** — Weighted by transaction count (code 183 at 99K txns matters more than code 110 at 4 txns).\n",
    "5. **Per-Layer** — Obvious (single GT mapping) vs Ambiguous (multi GT mapping) vs Unknown (no GT).\n",
    "6. **Failure Analysis** — Root cause patterns and prompt improvement recommendations.\n",
    "\n",
    "### Key Design Decisions\n",
    "- **Case-insensitive** — GT has `Debit card`, LLM outputs `Debit Card`. Both correct.\n",
    "- **Null-safe** — `None`, `NaN`, `null`, `N/A` all treated as equivalent.\n",
    "- **Multi-mapping** — 12 codes have 2+ valid GT mappings. LLM is correct if it matches ANY.\n",
    "- **GT normalization** — Fix casing inconsistencies (`Fee Item` → `Fee item`, `NSF /OD` → `NSF/OD`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "\n",
    "# ===========================================================================\n",
    "# CONFIGURATION — Update these paths for your environment\n",
    "# ===========================================================================\n",
    "RESULTS_PATH = \"../results/04_transaction_categorization_test.csv\"\n",
    "GT_PATH = \"../taxonomy/data/Master_Fee_Table_Master_.csv\"\n",
    "OUTPUT_DIR = \"../results\"\n",
    "\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "print(\"Configuration ready.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Load & Parse LLM Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw = pd.read_csv(RESULTS_PATH, dtype={\"TRANCD\": str})\n",
    "print(f\"Loaded {len(df_raw)} predictions.\")\n",
    "\n",
    "# Parse the JSON string in the 'parsed' column into separate columns\n",
    "parsed = df_raw[\"parsed\"].apply(json.loads).apply(pd.Series)\n",
    "\n",
    "df_res = pd.concat(\n",
    "    [df_raw[[\"TRANCD\", \"sample_desc_1\", \"volume\", \"source_file\"]], parsed], axis=1\n",
    ")\n",
    "\n",
    "# Prefix LLM columns so they're unambiguous after the merge\n",
    "df_res = df_res.rename(\n",
    "    columns={\n",
    "        \"category_1\": \"llm_L1\",\n",
    "        \"category_2\": \"llm_L2\",\n",
    "        \"category_3\": \"llm_L3\",\n",
    "        \"category_4\": \"llm_L4\",\n",
    "        \"include_in_scoring\": \"llm_scoring\",\n",
    "        \"credit_debit\": \"llm_credit_debit\",\n",
    "        \"confidence\": \"llm_confidence\",\n",
    "    }\n",
    ")\n",
    "\n",
    "print(f\"\\nLLM value distribution:\")\n",
    "for col in [\"llm_L1\", \"llm_L2\", \"llm_L3\", \"llm_L4\"]:\n",
    "    vals = sorted(df_res[col].dropna().unique())\n",
    "    print(f\"  {col}: {vals}\")\n",
    "\n",
    "df_res.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Load & Normalize Ground Truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gt_raw = pd.read_csv(GT_PATH, encoding=\"latin-1\")\n",
    "df_gt_raw.columns = [c.strip() for c in df_gt_raw.columns]\n",
    "\n",
    "# Drop rows that have no transaction code (header leaks, blanks)\n",
    "df_gt = df_gt_raw[\n",
    "    df_gt_raw[\"External Transaction Code\"].notna()\n",
    "    & (df_gt_raw[\"External Transaction Code\"].astype(str).str.strip() != \"\")\n",
    "].copy()\n",
    "\n",
    "df_gt[\"TRANCD\"]         = df_gt[\"External Transaction Code\"].astype(str).str.strip()\n",
    "df_gt[\"gt_desc\"]        = df_gt[\"External Transaction Description\"].str.strip()\n",
    "df_gt[\"gt_L1\"]          = df_gt[\"Scoring Category 1\"].str.strip()\n",
    "df_gt[\"gt_L2\"]          = df_gt[\"Scoring Category 2\"].str.strip()\n",
    "df_gt[\"gt_L3\"]          = df_gt[\"Scoring Category 3\"].str.strip()\n",
    "df_gt[\"gt_L4\"]          = df_gt[\"Scoring Category 4\"].str.strip()\n",
    "df_gt[\"gt_credit_debit\"] = df_gt[\"Credit / Debit\"].str.strip()\n",
    "\n",
    "print(f\"Raw GT: {len(df_gt)} rows, {df_gt['TRANCD'].nunique()} unique codes\")\n",
    "print(f\"\\nBEFORE normalization:\")\n",
    "print(f\"  L1 values: {sorted(df_gt['gt_L1'].dropna().unique())}\")\n",
    "print(f\"  L2 values: {sorted(df_gt['gt_L2'].dropna().unique())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Normalization maps ────────────────────────────────────────────\n",
    "#  Fix casing inconsistencies and leaked header rows.\n",
    "\n",
    "L1_NORM = {\n",
    "    \"Fee Item\":            \"Fee item\",\n",
    "    \"Fee item\":            \"Fee item\",\n",
    "    \"Non-fee item\":        \"Non-fee item\",\n",
    "    \"Scoring Category 1\":  None,           # header row leak\n",
    "}\n",
    "\n",
    "L2_NORM = {\n",
    "    \"NSF /OD\":             \"NSF/OD\",\n",
    "    \"NSF/OD\":              \"NSF/OD\",\n",
    "    \"Money Movement\":      \"Money movement\",\n",
    "    \"Money movement\":      \"Money movement\",\n",
    "    \"Account Operations\":  \"Account operations\",\n",
    "    \"Account operations\":  \"Account operations\",\n",
    "    \"All others\":          \"All others\",\n",
    "    \"Service Charges\":     \"Service Charges\",\n",
    "    \"Scoring Category 2\":  None,           # header row leak\n",
    "}\n",
    "\n",
    "L3_NORM = {\"N/A\": None, \"Money Movement\": \"Money movement\", \"Account Operations\": \"Account operations\"}\n",
    "L4_NORM = {\"N/A\": None}\n",
    "\n",
    "df_gt[\"gt_L1\"] = df_gt[\"gt_L1\"].map(L1_NORM).fillna(df_gt[\"gt_L1\"])\n",
    "df_gt[\"gt_L2\"] = df_gt[\"gt_L2\"].map(L2_NORM).fillna(df_gt[\"gt_L2\"])\n",
    "df_gt[\"gt_L3\"] = df_gt[\"gt_L3\"].map(L3_NORM).fillna(df_gt[\"gt_L3\"])\n",
    "df_gt[\"gt_L4\"] = df_gt[\"gt_L4\"].map(L4_NORM).fillna(df_gt[\"gt_L4\"])\n",
    "\n",
    "# Drop header-leak rows (L1 mapped to None)\n",
    "df_gt = df_gt[df_gt[\"gt_L1\"].notna()].copy()\n",
    "\n",
    "print(f\"After normalization: {len(df_gt)} rows, {df_gt['TRANCD'].nunique()} unique codes\")\n",
    "print(f\"\\nAFTER normalization:\")\n",
    "print(f\"  L1 values: {sorted(df_gt['gt_L1'].dropna().unique())}\")\n",
    "print(f\"  L2 values: {sorted(df_gt['gt_L2'].dropna().unique())}\")\n",
    "print(f\"  L3 values: {sorted(df_gt['gt_L3'].dropna().unique())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Assign Test Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify multi-mapping codes (same TRANCD → 2+ distinct categorizations)\n",
    "gt_mapping_counts = (\n",
    "    df_gt.groupby(\"TRANCD\")\n",
    "    .apply(lambda g: g[[\"gt_L1\", \"gt_L2\", \"gt_L3\", \"gt_L4\"]].drop_duplicates().shape[0])\n",
    "    .reset_index(name=\"n_mappings\")\n",
    ")\n",
    "\n",
    "multi_codes  = set(gt_mapping_counts.loc[gt_mapping_counts[\"n_mappings\"] > 1, \"TRANCD\"])\n",
    "single_codes = set(gt_mapping_counts.loc[gt_mapping_counts[\"n_mappings\"] == 1, \"TRANCD\"])\n",
    "all_gt_codes = set(df_gt[\"TRANCD\"].unique())\n",
    "\n",
    "def assign_layer(trancd):\n",
    "    if trancd not in all_gt_codes:\n",
    "        return \"Layer 3: Unknown\"\n",
    "    if trancd in multi_codes:\n",
    "        return \"Layer 2: Ambiguous\"\n",
    "    return \"Layer 1: Obvious\"\n",
    "\n",
    "df_res[\"test_layer\"] = df_res[\"TRANCD\"].apply(assign_layer)\n",
    "\n",
    "layer_summary = (\n",
    "    df_res.groupby(\"test_layer\")\n",
    "    .agg(codes=(\"TRANCD\", \"nunique\"), total_volume=(\"volume\", \"sum\"))\n",
    "    .reset_index()\n",
    ")\n",
    "layer_summary[\"pct_volume\"] = (\n",
    "    layer_summary[\"total_volume\"] / layer_summary[\"total_volume\"].sum() * 100\n",
    ").round(1)\n",
    "print(\"Test-layer distribution:\")\n",
    "print(layer_summary.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Comparison Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Case-insensitive, null-safe comparison ────────────────────────\n",
    "\n",
    "_NULL = \"__null__\"\n",
    "\n",
    "def _canon(val):\n",
    "    \"\"\"Canonicalize a value for comparison: lowercase, strip, null-safe.\"\"\"\n",
    "    if val is None or (isinstance(val, float) and np.isnan(val)):\n",
    "        return _NULL\n",
    "    s = str(val).strip().lower()\n",
    "    if s in (\"\", \"none\", \"nan\", \"null\", \"n/a\"):\n",
    "        return _NULL\n",
    "    return s\n",
    "\n",
    "\n",
    "def levels_match(row, llm_col, gt_col):\n",
    "    return _canon(row[llm_col]) == _canon(row[gt_col])\n",
    "\n",
    "\n",
    "def add_match_columns(df):\n",
    "    \"\"\"Add per-level and aggregate match booleans.\"\"\"\n",
    "    df = df.copy()\n",
    "    df[\"match_L1\"] = df.apply(levels_match, axis=1, llm_col=\"llm_L1\", gt_col=\"gt_L1\")\n",
    "    df[\"match_L2\"] = df.apply(levels_match, axis=1, llm_col=\"llm_L2\", gt_col=\"gt_L2\")\n",
    "    df[\"match_L3\"] = df.apply(levels_match, axis=1, llm_col=\"llm_L3\", gt_col=\"gt_L3\")\n",
    "    df[\"match_L4\"] = df.apply(levels_match, axis=1, llm_col=\"llm_L4\", gt_col=\"gt_L4\")\n",
    "\n",
    "    df[\"exact_match\"]        = df[[\"match_L1\", \"match_L2\", \"match_L3\", \"match_L4\"]].all(axis=1)\n",
    "    df[\"partial_match_L1L2\"] = df[[\"match_L1\", \"match_L2\"]].all(axis=1)\n",
    "    df[\"partial_match_L1L2L3\"] = df[[\"match_L1\", \"match_L2\", \"match_L3\"]].all(axis=1)\n",
    "    return df\n",
    "\n",
    "\n",
    "print(\"Helpers ready.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Layer 1 — Obvious Codes (Single Mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build GT lookup for single-mapping codes (1 row per TRANCD)\n",
    "gt_cols = [\"TRANCD\", \"gt_desc\", \"gt_L1\", \"gt_L2\", \"gt_L3\", \"gt_L4\", \"gt_credit_debit\"]\n",
    "df_gt_single = (\n",
    "    df_gt[df_gt[\"TRANCD\"].isin(single_codes)]\n",
    "    .drop_duplicates(subset=\"TRANCD\", keep=\"first\")[gt_cols]\n",
    ")\n",
    "\n",
    "# Merge\n",
    "df_l1 = pd.merge(\n",
    "    df_res[df_res[\"test_layer\"] == \"Layer 1: Obvious\"],\n",
    "    df_gt_single,\n",
    "    on=\"TRANCD\",\n",
    "    how=\"left\",\n",
    ")\n",
    "\n",
    "df_l1 = add_match_columns(df_l1)\n",
    "n = len(df_l1)\n",
    "\n",
    "print(\"=\" * 65)\n",
    "print(f\"LAYER 1 — OBVIOUS CODES  (n = {n})\")\n",
    "print(\"=\" * 65)\n",
    "print(f\"  L1 (Fee vs Non-fee):      {df_l1['match_L1'].mean():.1%}\")\n",
    "print(f\"  L2 (Category):            {df_l1['match_L2'].mean():.1%}\")\n",
    "print(f\"  L3 (Channel):             {df_l1['match_L3'].mean():.1%}\")\n",
    "print(f\"  L4 (Subtype):             {df_l1['match_L4'].mean():.1%}\")\n",
    "print(f\"  ─────────────────────────────\")\n",
    "print(f\"  Partial (L1+L2):          {df_l1['partial_match_L1L2'].mean():.1%}\")\n",
    "print(f\"  Partial (L1+L2+L3):       {df_l1['partial_match_L1L2L3'].mean():.1%}\")\n",
    "print(f\"  Exact Match (all 4):      {df_l1['exact_match'].mean():.1%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Volume-weighted accuracy ──────────────────────────────────────\n",
    "vol = df_l1[\"volume\"].sum()\n",
    "\n",
    "print(\"=\" * 65)\n",
    "print(f\"VOLUME-WEIGHTED ACCURACY  (total: {vol:,} transactions)\")\n",
    "print(\"=\" * 65)\n",
    "\n",
    "for col, label in [\n",
    "    (\"match_L1\",            \"L1 (Fee vs Non-fee)\"),\n",
    "    (\"match_L2\",            \"L2 (Category)\"),\n",
    "    (\"match_L3\",            \"L3 (Channel)\"),\n",
    "    (\"match_L4\",            \"L4 (Subtype)\"),\n",
    "    (\"partial_match_L1L2\",  \"Partial (L1+L2)\"),\n",
    "    (\"exact_match\",         \"Exact (all 4)\"),\n",
    "]:\n",
    "    w = (df_l1[col] * df_l1[\"volume\"]).sum() / vol\n",
    "    print(f\"  {label:<25} {w:.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Layer 2 — Ambiguous Codes (Multi-Mapping)\n",
    "\n",
    "A prediction is correct if it matches **any** of the valid GT mappings for that code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_l2_src = df_res[df_res[\"test_layer\"] == \"Layer 2: Ambiguous\"].copy()\n",
    "\n",
    "rows = []\n",
    "for _, row in df_l2_src.iterrows():\n",
    "    code = row[\"TRANCD\"]\n",
    "    gt_maps = (\n",
    "        df_gt[df_gt[\"TRANCD\"] == code][[\"gt_L1\", \"gt_L2\", \"gt_L3\", \"gt_L4\"]]\n",
    "        .drop_duplicates()\n",
    "    )\n",
    "    llm = tuple(_canon(row[c]) for c in [\"llm_L1\", \"llm_L2\", \"llm_L3\", \"llm_L4\"])\n",
    "\n",
    "    best_levels = 0\n",
    "    matched_any = False\n",
    "    for _, g in gt_maps.iterrows():\n",
    "        gt = tuple(_canon(g[c]) for c in [\"gt_L1\", \"gt_L2\", \"gt_L3\", \"gt_L4\"])\n",
    "        n_match = sum(a == b for a, b in zip(llm, gt))\n",
    "        best_levels = max(best_levels, n_match)\n",
    "        if llm == gt:\n",
    "            matched_any = True\n",
    "\n",
    "    rows.append(\n",
    "        {\n",
    "            \"TRANCD\": code,\n",
    "            \"description\": row[\"sample_desc_1\"],\n",
    "            \"volume\": row[\"volume\"],\n",
    "            \"llm_path\": f\"{row['llm_L1']} > {row['llm_L2']} > {row['llm_L3']}\",\n",
    "            \"exact_match_any\": matched_any,\n",
    "            \"best_levels_matched\": best_levels,\n",
    "            \"n_valid_mappings\": len(gt_maps),\n",
    "            \"confidence\": row[\"llm_confidence\"],\n",
    "        }\n",
    "    )\n",
    "\n",
    "df_l2 = pd.DataFrame(rows)\n",
    "\n",
    "print(\"=\" * 65)\n",
    "print(f\"LAYER 2 — AMBIGUOUS CODES  (n = {len(df_l2)})\")\n",
    "print(\"=\" * 65)\n",
    "print(f\"  Exact match (any valid mapping):  {df_l2['exact_match_any'].mean():.1%}\")\n",
    "print(f\"  Avg best levels matched:          {df_l2['best_levels_matched'].mean():.1f} / 4\")\n",
    "print()\n",
    "print(df_l2.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show all valid GT mappings for each ambiguous code\n",
    "print(\"\\nValid GT mappings for ambiguous codes in our results:\")\n",
    "for code in sorted(df_l2[\"TRANCD\"].unique()):\n",
    "    maps = (\n",
    "        df_gt[df_gt[\"TRANCD\"] == code][[\"gt_desc\", \"gt_L1\", \"gt_L2\", \"gt_L3\"]]\n",
    "        .drop_duplicates()\n",
    "    )\n",
    "    llm_row = df_l2_src[df_l2_src[\"TRANCD\"] == code].iloc[0]\n",
    "    print(f\"\\n  TRANCD={code}  (LLM: {llm_row['llm_L1']} > {llm_row['llm_L2']} > {llm_row['llm_L3']})\")\n",
    "    for _, m in maps.iterrows():\n",
    "        print(f\"    GT: {m['gt_L1']:<15} > {m['gt_L2']:<22} > {str(m['gt_L3']):<25} | {m['gt_desc'][:45]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. Layer 3 — Unknown Codes (No Ground Truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_l3 = df_res[df_res[\"test_layer\"] == \"Layer 3: Unknown\"].copy()\n",
    "\n",
    "print(\"=\" * 65)\n",
    "print(f\"LAYER 3 — UNKNOWN CODES  (n = {len(df_l3)}, no ground truth)\")\n",
    "print(\"=\" * 65)\n",
    "print(\"These need manual review by Sid / Mike.\\n\")\n",
    "\n",
    "for _, r in df_l3.sort_values(\"volume\", ascending=False).iterrows():\n",
    "    print(f\"  TRANCD={r['TRANCD']:>5} | vol={r['volume']:>6,} | conf={r['llm_confidence']}\")\n",
    "    print(f\"    desc: {r['sample_desc_1']}\")\n",
    "    print(f\"    LLM:  {r['llm_L1']} > {r['llm_L2']} > {r['llm_L3']} > {r['llm_L4']}\")\n",
    "    print(f\"    scoring: {r['llm_scoring']}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 8. Failure Analysis — Layer 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "failures = df_l1[~df_l1[\"exact_match\"]].copy()\n",
    "\n",
    "def failure_type(row):\n",
    "    if not row[\"match_L1\"]:\n",
    "        return \"WRONG BLOCK (L1)\"\n",
    "    if not row[\"match_L2\"]:\n",
    "        return \"WRONG CATEGORY (L2)\"\n",
    "    if not row[\"match_L3\"]:\n",
    "        return \"WRONG CHANNEL (L3)\"\n",
    "    if not row[\"match_L4\"]:\n",
    "        return \"WRONG SUBTYPE (L4)\"\n",
    "    return \"UNKNOWN\"\n",
    "\n",
    "failures[\"failure_type\"] = failures.apply(failure_type, axis=1)\n",
    "\n",
    "print(\"=\" * 65)\n",
    "print(f\"FAILURE ANALYSIS — {len(failures)} mismatches out of {len(df_l1)} obvious codes\")\n",
    "print(\"=\" * 65)\n",
    "\n",
    "ft = (\n",
    "    failures.groupby(\"failure_type\")\n",
    "    .agg(\n",
    "        count=(\"TRANCD\", \"count\"),\n",
    "        volume=(\"volume\", \"sum\"),\n",
    "        examples=(\"TRANCD\", lambda x: \", \".join(x.head(4))),\n",
    "    )\n",
    "    .sort_values(\"count\", ascending=False)\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "print(\"\\nFailure type distribution:\")\n",
    "print(ft.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Detailed mismatch table ───────────────────────────────────────\n",
    "\n",
    "print(\"\\n\" + \"=\" * 65)\n",
    "print(\"DETAILED FAILURES (sorted by volume, highest impact first)\")\n",
    "print(\"=\" * 65)\n",
    "\n",
    "for _, r in failures.sort_values(\"volume\", ascending=False).iterrows():\n",
    "    print(\n",
    "        f\"\\n  TRANCD={r['TRANCD']:>5} | vol={r['volume']:>6,}\"\n",
    "        f\" | conf={r['llm_confidence']} | {r['failure_type']}\"\n",
    "    )\n",
    "    print(f\"    sample desc:  {r['sample_desc_1'][:55]}\")\n",
    "    print(f\"    gt desc:      {str(r['gt_desc'])[:55]}\")\n",
    "\n",
    "    for lvl in [\"L1\", \"L2\", \"L3\", \"L4\"]:\n",
    "        llm_val = str(r[f\"llm_{lvl}\"])\n",
    "        gt_val  = str(r[f\"gt_{lvl}\"])\n",
    "        ok      = \"Y\" if r[f\"match_{lvl}\"] else \"X\"\n",
    "        if not r[f\"match_{lvl}\"]:\n",
    "            print(f'    {lvl}: [{ok}] LLM=\"{llm_val}\" vs GT=\"{gt_val}\"')\n",
    "        else:\n",
    "            print(f'    {lvl}: [{ok}] \"{llm_val}\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Root-cause: uninformative descriptions ────────────────────────\n",
    "\n",
    "unclassified = df_l1[df_l1[\"llm_L2\"] == \"Unclassified\"]\n",
    "\n",
    "print(\"=\" * 65)\n",
    "print(\"ROOT CAUSE: Uninformative descriptions (LLM → 'Unclassified')\")\n",
    "print(\"=\" * 65)\n",
    "if len(unclassified) > 0:\n",
    "    print(f\"\\n{len(unclassified)} codes where the sample_desc_1 was an address,\")\n",
    "    print(\"a person name, or other non-descriptive text:\\n\")\n",
    "    for _, r in unclassified.iterrows():\n",
    "        print(\n",
    "            f'  TRANCD={r[\"TRANCD\"]:>5} '\n",
    "            f'| \"{r[\"sample_desc_1\"][:35]}\" '\n",
    "            f'| GT: {r[\"gt_L2\"]} > {r[\"gt_L3\"]}'\n",
    "        )\n",
    "    vol_pct = unclassified[\"volume\"].sum() / df_l1[\"volume\"].sum() * 100\n",
    "    print(f\"\\n  Volume impact: {unclassified['volume'].sum():,} txns ({vol_pct:.1f}%)\")\n",
    "    print(\"  Fix: Feed the GT description from the Master Fee Table, not raw EFHDS1.\")\n",
    "else:\n",
    "    print(\"None — all codes received a classification.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 9. Summary Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vol_total   = df_res[\"volume\"].sum()\n",
    "vol_l1      = df_l1[\"volume\"].sum()\n",
    "vw_exact    = (df_l1[\"exact_match\"] * df_l1[\"volume\"]).sum() / vol_l1\n",
    "vw_partial  = (df_l1[\"partial_match_L1L2\"] * df_l1[\"volume\"]).sum() / vol_l1\n",
    "amb_match   = df_l2[\"exact_match_any\"].mean() if len(df_l2) > 0 else 0\n",
    "n_uncl      = len(unclassified) if \"unclassified\" in dir() else 0\n",
    "n_wrong_blk = len(failures[failures[\"failure_type\"] == \"WRONG BLOCK (L1)\"])\n",
    "target_met  = vw_exact >= 0.80\n",
    "status      = \"MET\" if target_met else \"BELOW TARGET\"\n",
    "\n",
    "print(\"=\" * 65)\n",
    "print(\"  TRANSACTION CATEGORIZATION — ACCURACY SUMMARY\")\n",
    "print(\"=\" * 65)\n",
    "print(f\"\")\n",
    "print(f\"  Total codes tested:              {len(df_res)}\")\n",
    "print(f\"  Total transaction volume:         {vol_total:,}\")\n",
    "print(f\"\")\n",
    "print(f\"  LAYER 1 — Obvious (single-mapping)\")\n",
    "print(f\"    Codes: {len(df_l1)}    Volume: {vol_l1:,}\")\n",
    "print(f\"    L1 (Block):           {df_l1['match_L1'].mean():.1%}\")\n",
    "print(f\"    L2 (Category):        {df_l1['match_L2'].mean():.1%}\")\n",
    "print(f\"    L3 (Channel):         {df_l1['match_L3'].mean():.1%}\")\n",
    "print(f\"    L4 (Subtype):         {df_l1['match_L4'].mean():.1%}\")\n",
    "print(f\"    Exact Match (all 4):  {df_l1['exact_match'].mean():.1%}  (vol-wt: {vw_exact:.1%})\")\n",
    "print(f\"    Partial (L1+L2):      {df_l1['partial_match_L1L2'].mean():.1%}  (vol-wt: {vw_partial:.1%})\")\n",
    "print(f\"\")\n",
    "print(f\"  LAYER 2 — Ambiguous: {len(df_l2)} codes\")\n",
    "print(f\"    Match (any valid):    {amb_match:.1%}\")\n",
    "print(f\"\")\n",
    "print(f\"  LAYER 3 — Unknown: {len(df_l3)} codes (manual review)\")\n",
    "print(f\"\")\n",
    "print(f\"  KEY FAILURES:\")\n",
    "print(f\"    Uninformative descriptions:  {n_uncl} codes -> 'Unclassified'\")\n",
    "print(f\"    Wrong block (L1):            {n_wrong_blk} codes\")\n",
    "print(f\"\")\n",
    "print(f\"  TARGET: >=80% vol-weighted exact match -> {status}\")\n",
    "print(\"=\" * 65)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 10. Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Layer 1 — with all match columns\n",
    "df_l1.to_csv(f\"{OUTPUT_DIR}/eval_layer1_obvious.csv\", index=False)\n",
    "\n",
    "# Layer 2 — ambiguous summary\n",
    "df_l2.to_csv(f\"{OUTPUT_DIR}/eval_layer2_ambiguous.csv\", index=False)\n",
    "\n",
    "# Layer 3 — for manual review\n",
    "df_l3[\"review_status\"] = \"NEEDS MANUAL REVIEW\"\n",
    "df_l3.to_csv(f\"{OUTPUT_DIR}/eval_layer3_unknown.csv\", index=False)\n",
    "\n",
    "# Combined\n",
    "df_all = pd.concat([df_l1, df_l2, df_l3], ignore_index=True, sort=False)\n",
    "df_all.to_csv(f\"{OUTPUT_DIR}/eval_full_report.csv\", index=False)\n",
    "\n",
    "print(f\"Reports saved to {OUTPUT_DIR}/\")\n",
    "print(f\"  eval_layer1_obvious.csv    ({len(df_l1)} rows)\")\n",
    "print(f\"  eval_layer2_ambiguous.csv  ({len(df_l2)} rows)\")\n",
    "print(f\"  eval_layer3_unknown.csv    ({len(df_l3)} rows)\")\n",
    "print(f\"  eval_full_report.csv       ({len(df_all)} rows)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 11. Next-Iteration Prompt Improvements\n",
    "\n",
    "Based on the failure analysis, concrete fixes for the next `ai_query` run:\n",
    "\n",
    "### Fix 1 — Uninformative descriptions\n",
    "Codes 237, 242, 261, 283, 299 have street addresses as `sample_desc_1` (e.g., `306 W BROADWAY ST`). The LLM has zero signal and defaults to `Unclassified`.  \n",
    "**Fix:** Include a TRANCD → canonical-description lookup table in the prompt. Map `237 → ATM W/D`, `283 → ATM Deposit`, etc. from the Master Fee Table.\n",
    "\n",
    "### Fix 2 — ACH returns mis-classified as NSF/OD\n",
    "Codes 8 and 59 (`ORIGINATED ACH ITEM RETURNED`, `No Account/Unable to Locate`) were classified as NSF/OD but the GT says `Money movement > ACH`.  \n",
    "**Fix:** Add few-shot: `\"ACH returns and rejects are Money movement > ACH, not NSF/OD.\"`\n",
    "\n",
    "### Fix 3 — Account operations vs Money movement\n",
    "Codes 918/919 (`Trnsfr Frm Act Ending in...`) look like transfers but GT says `Account operations > Closing`. Same with 741/744 (`Investment Sweep`).  \n",
    "**Fix:** Add rule: `\"Account closings, investment sweeps, and IRA distributions are Account operations, not Money movement.\"`\n",
    "\n",
    "### Fix 4 — L3 casing drift\n",
    "The LLM outputs `Debit Card` while the taxonomy uses `Debit card`.  \n",
    "**Fix:** Add explicit instruction: `\"Use these EXACT L3 strings: ACH, ATM, Check, Debit card, Wire, Transfers & Payments, Deposits, Withdrawals, Interest, Closing, Misc.\"`\n",
    "\n",
    "### Fix 5 — Code 334 (Service Charge Refund)\n",
    "The prompt rule \"Refunds/Reversals of fees → Block A > Money movement > Deposits\" overrode the GT mapping `Fee item > All others > Account Operations`.  \n",
    "**Fix:** Check with Sid/Mike whether the prompt rule or the GT is correct, then align."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

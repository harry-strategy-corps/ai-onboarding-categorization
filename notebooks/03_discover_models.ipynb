{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f0a03a4e-65b9-4fef-a064-fb937a70d3d5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# 03 â€” Discover Available Models\n",
    "\n",
    "**Objective:** Enumerate the model serving endpoints available in the current Databricks workspace and verify that `ai_query()` and `ai_classify()` are functioning correctly.\n",
    "\n",
    "### Why this matters:\n",
    "The available foundation models (Llama, Claude, DBRX, etc.) vary by region and workspace configuration. We need to identify which model to use for the categorization task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6cdaba2a-27f4-493a-b787-212f000f3ed4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 1. List Serving Endpoints\n",
    "Run this cell in a Databricks environment to see available foundation models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "840a5628-8e46-422a-9717-25731d488815",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Note: This requires databricks-sdk\n",
    "try:\n",
    "    from databricks.sdk import WorkspaceClient\n",
    "    w = WorkspaceClient()\n",
    "    print(\"Available Serving Endpoints:\")\n",
    "    for endpoint in w.serving_endpoints.list():\n",
    "        print(f\"- {endpoint.name} ({endpoint.state.config_update})\")\n",
    "except Exception as e:\n",
    "    print(f\"Could not list endpoints via SDK: {e}\")\n",
    "    print(\"Try running SQL 'SHOW SERVING ENDPOINTS' if available, or check the 'Serving' UI.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d40b1144-9a0f-43e6-8133-e22d5826e058",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 2. Test `ai_classify()`\n",
    "Verify the task-specific classification function works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "851a6011-7237-4d14-bd1f-b6905c9ba678",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# In Databricks, you can run this as a SQL cell or via spark.sql()\n",
    "test_classify_sql = \"\"\"\n",
    "SELECT ai_classify(\"Business Elite Checking\", ARRAY(\"Checking\", \"Savings\", \"CD\", \"Money Market\", \"Loan\"))\n",
    "\"\"\"\n",
    "try:\n",
    "    display(spark.sql(test_classify_sql))\n",
    "except NameError:\n",
    "    print(\"Spark session not found. Run this in a Databricks notebook cell.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7f43f5d4-2d9d-497a-8e10-7c3bdf48eddf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 3. Test `ai_query()`\n",
    "Verify the general-purpose LLM function works. Replace the model name if needed based on the output of Step 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f5dd70d3-8737-4024-b1b4-366f4662c9a2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Common Databricks model names:\n",
    "# - databricks-meta-llama-3-1-70b-instruct\n",
    "# - databricks-meta-llama-3-1-405b-instruct\n",
    "# - databricks-dbrx-instruct\n",
    "\n",
    "model_name = \"databricks-meta-llama-3-3-70b-instruct\" \n",
    "\n",
    "test_query_sql = f\"\"\"\n",
    "SELECT ai_query(\n",
    "  '{model_name}',\n",
    "  'Classify this bank transaction as Fee or Non-fee: ATM Withdrawal. Return only one word.'\n",
    ")\n",
    "\"\"\"\n",
    "try:\n",
    "    display(spark.sql(test_query_sql))\n",
    "except NameError:\n",
    "    print(\"Spark session not found. Run this in a Databricks notebook cell.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a11f7f0a-696e-4b6b-9dfb-94c972493a95",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 4. Conclusion\n",
    "Document the chosen model and endpoint for use in the next notebook."
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "03_discover_models",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
